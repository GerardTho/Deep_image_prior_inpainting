{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git clone https://github.com/GerardTho/Deep_image_prior_inpainting.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cd Deep_image_prior_inpainting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "89TgOrNuQo_H"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wande\\anaconda3\\envs\\DeepImagePrior\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] La procédure spécifiée est introuvable'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import utils\n",
        "from model.EncoderDecoder import EncoderDecoder\n",
        "from model.EncoderDecoderSkipConnections import EncoderDecoderSkipConnections\n",
        "from model.EncoderDecoderResidualConnections import EncoderDecoderResidualConnections\n",
        "from model.EdgeModeInpainting import InpaintGenerator, EdgeGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Image Prior Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Iza4W3_TGakY"
      },
      "outputs": [],
      "source": [
        "input_depth = 32\n",
        "LR = 0.01\n",
        "num_iter = 5000\n",
        "show_every = 100\n",
        "figsize = 5\n",
        "reg_noise_std = 0.03\n",
        "OPTIMIZER = 'adam'\n",
        "model_selection = \"EncoderDecoder\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G2Vu23capjgx"
      },
      "outputs": [],
      "source": [
        "img_path  = 'data/stairs.jpg'\n",
        "mask_path = 'data/stairs_mask.jpg'\n",
        "img_pil, img_np = utils.get_image(img_path)\n",
        "img_mask_pil, img_mask_np = utils.get_image(mask_path)\n",
        "img_mask_pil = utils.crop_image(img_mask_pil, d=64)\n",
        "img_pil      = utils.crop_image(img_pil, d=64)\n",
        "img_np      = utils.pil_to_np(img_pil)\n",
        "img_mask_np = utils.pil_to_np(img_mask_pil)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1WM93CHnnLdd"
      },
      "outputs": [],
      "source": [
        "if model_selection == \"EncoderDecoder\":\n",
        "    model = EncoderDecoder(num_input_channels=input_depth, num_output_channels=img_np.shape[0],\n",
        "                        n_upsampler=[128, 128, 128, 64, 32, 16],\n",
        "                        n_downsampler=[16, 32, 64, 128, 128, 128],\n",
        "                        k_upsampler=[3, 3, 3, 3, 3, 3],\n",
        "                        k_downsampler=[5, 5, 5, 5, 5, 5],).to(device)\n",
        "elif model_selection == \"EncoderDecoderSkipConnections\":\n",
        "    model = EncoderDecoderSkipConnections(num_input_channels=input_depth, num_output_channels=img_np.shape[0],\n",
        "                        n_upsampler=[128, 128, 128, 64, 32, 16],\n",
        "                        n_downsampler=[16, 32, 64, 128, 128, 128],\n",
        "                        n_skip=[0,0,0,0,0,0],\n",
        "                        k_upsampler=[3, 3, 3, 3, 3, 3],\n",
        "                        k_downsampler=[5, 5, 5, 5, 5, 5],\n",
        "                        k_skip=[1,1,1,1,1,1],).to(device)\n",
        "elif model_selection == \"EncoderDecoderResidualConnections\":\n",
        "    model = EncoderDecoderResidualConnections(num_input_channels=input_depth, num_output_channels=img_np.shape[0],\n",
        "                        n_upsampler=[128, 128, 128, 64, 32, 16],\n",
        "                        n_downsampler=[16, 32, 64, 128, 128, 128],\n",
        "                        k_upsampler=[3, 3, 3, 3, 3, 3],\n",
        "                        k_downsampler=[5, 5, 5, 5, 5, 5],).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y77nJeHpGjK0",
        "outputId": "ea468c89-471d-4da5-cf48-d2d016015910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of params: 3167363\n"
          ]
        }
      ],
      "source": [
        "# Compute number of parameters\n",
        "s  = sum(np.prod(list(p.size())) for p in model.parameters())\n",
        "print ('Number of params: %d' % s)\n",
        "\n",
        "img_var = torch.from_numpy(img_np).reshape(-1, img_np.shape[0], img_np.shape[1], img_np.shape[2]).to(device)\n",
        "mask_var = torch.from_numpy(img_mask_np).reshape(-1, img_mask_np.shape[0], img_mask_np.shape[1], img_mask_np.shape[2]).to(device)\n",
        "\n",
        "# Loss\n",
        "mse = torch.nn.MSELoss()\n",
        "\n",
        "net_input = utils.generate_noise_uniform(input_depth, img_np.shape[1:]).reshape(1, -1, img_np.shape[1], img_np.shape[2] ).to(torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdfluvT9uKO-"
      },
      "outputs": [],
      "source": [
        "def optimize(parameters, LR, num_iter):\n",
        "  optimizer = torch.optim.Adam(parameters, lr=LR)\n",
        "  for j in range(num_iter):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    net_input = net_input_saved\n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "\n",
        "    out = model(net_input)\n",
        "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
        "    total_loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    print ('Iteration %05d    Loss %f' % (j, total_loss.item()), '\\r', end='')\n",
        "    if j % show_every == 0:\n",
        "        out_np = out.detach().cpu().numpy()[0]\n",
        "        utils.plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n",
        "  # Return last iteration\n",
        "  return out_np\n",
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "\n",
        "p = [x for x in model.parameters()]\n",
        "out_np = optimize(p, LR, num_iter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "hhAwY9-fi-lN",
        "outputId": "a9e812ca-2b1b-4531-fe50-82fc356f8374"
      },
      "outputs": [],
      "source": [
        "out_np = model(net_input).detach().cpu().numpy()[0]\n",
        "utils.plot_image_grid([out_np], factor=5);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.PSNR(img_np, out_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Edge Connect Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_path  = 'data/wall.jpg'\n",
        "mask_path = 'data/wall_small_hole_mask.jpg'\n",
        "img_pil, img_np = utils.get_image(img_path)\n",
        "img_pil.thumbnail((256, 256), Image.Resampling.LANCZOS)\n",
        "img_mask_pil, img_mask_np = utils.get_image(mask_path)\n",
        "img_mask_pil.thumbnail((256, 256), Image.Resampling.LANCZOS)\n",
        "img_mask_pil = utils.crop_image(img_mask_pil)\n",
        "img_pil      = utils.crop_image(img_pil)\n",
        "img_np      = utils.pil_to_np(img_pil)\n",
        "img_mask_np = utils.pil_to_np(img_mask_pil)\n",
        "img_masked = img_np*img_mask_np + (1-img_mask_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edge_model = EdgeGenerator(init_weights=False)\n",
        "edge_model.load_state_dict(torch.load('pretrained_GAN/EdgeModel_gen.pth', map_location=device)[\"generator\"])\n",
        "inpaint_model = InpaintGenerator(init_weights=False)\n",
        "inpaint_model.load_state_dict(torch.load('pretrained_GAN/InpaintingModel_gen.pth', map_location=device)[\"generator\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_edge = edge_model(torch.from_numpy(1-img_np))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "img_inpainted = inpaint_model(torch.cat((torch.from_numpy(img_masked), img_edge), dim=0)).detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.plot_image_grid([np.clip(1-img_edge.detach().cpu().numpy(), 0, 1)], factor=figsize, nrow=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.plot_image_grid([np.clip(img_inpainted, 0, 1)], factor=figsize, nrow=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.PSNR(img_np ,img_inpainted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
